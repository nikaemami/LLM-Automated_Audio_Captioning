- ++model_config.llm_name=vicuna-7b-v1.5
- ++model_config.llm_path=lmsys/vicuna-7b-v1.5
- ++model_config.llm_dim=4096
- ++model_config.encoder_name=none
- ++model_config.encoder_path=none
- ++model_config.encoder_dim=64
- ++model_config.encoder_projector=q-former
- ++model_config.encoder_projector_ds_rate=5
- ++dataset_config.encoder_projector_ds_rate=5
- ++dataset_config.encoder_dim=64
- ++dataset_config.dataset=h5_audio_dataset
- ++dataset_config.file=examples/slam_aac/utils/h5_dataset.py:get_h5_audio_dataset
- ++dataset_config.h5_val_file_path=/gpfs/scratch/cl6707/Shared/clotho/clotho_evaluation.h5
- ++dataset_config.feature_type=mel_spectrogram
- ++dataset_config.val_data_path=/gpfs/scratch/cl6707/Shared/clotho/clotho_evaluation.h5
- ++dataset_config.inference_mode=true
- ++dataset_config.fixed_length=true
- ++dataset_config.target_length=1024
- ++dataset_config.prompt=Describe the audio you hear.
- ++train_config.model_name=aac
- ++train_config.batching_strategy=custom
- ++train_config.num_epochs=1
- ++train_config.val_batch_size=4
- ++train_config.num_workers_dataloader=0
- ++train_config.output_dir=/gpfs/scratch/cl6707/Projects/LLM-AAC/exps/Clotho/slam-aac_Clotho_qformer_h5_mel_spectrogram/inference_clap_refined
- ++train_config.freeze_encoder=true
- ++train_config.freeze_llm=true
- ++train_config.use_peft=false
- ++ckpt_path=/gpfs/scratch/cl6707/Projects/LLM-AAC/exps/Clotho/slam-aac_Clotho_qformer_h5_mel_spectrogram/model.pt
- ++decode_log=/gpfs/scratch/cl6707/Projects/LLM-AAC/exps/Clotho/slam-aac_Clotho_qformer_h5_mel_spectrogram/inference_clap_refined/decode_beam4
- ++model_config.num_beams=4
- ++log_config.log_file=/gpfs/scratch/cl6707/Projects/LLM-AAC/exps/Clotho/slam-aac_Clotho_qformer_h5_mel_spectrogram/inference_clap_refined/inference.log
